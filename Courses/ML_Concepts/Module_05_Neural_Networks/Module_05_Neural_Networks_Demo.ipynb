{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICBI/AIMAHEAD_GU/blob/main/Courses/ML_Concepts/Module_05_Neural_Networks/Module_05_Neural_Networks_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ICBI/AIMAHEAD_GU_publicCourseData/main/AAlogo1.jpg\" alt=\"Powered by\" width=\"150\"/>\n",
        "\n",
        "# AI/ML for Healthcare Applications : Lab 5 Neural Networks Demo\n",
        "\n",
        "Based on material from the Georgetown [Health Informatics and Data Science](https://healthinformatics.georgetown.edu) program and licensed under  [CC4.0](https://creativecommons.org/licenses/by/4.0/)\n"
      ],
      "metadata": {
        "id": "rvSwRkGI9IfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we will explore how to use neural networks for classification using sklearn and a popular deep learning library: Keras/TensorFlow"
      ],
      "metadata": {
        "id": "sw8BT1ZD9boD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some imports"
      ],
      "metadata": {
        "id": "xO_H0YVW9yaB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKYgQsmF83YG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rcParams['figure.figsize'] = (10, 10)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "mN7f2iTULdYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(predictions_proba, threshold=0.5):\n",
        "  predictions = np.where(predictions_proba <= threshold, 0, 1)\n",
        "  return predictions\n",
        "\n",
        "#Function that calculates and print metrics\n",
        "def show_metrics(testy, predictions):\n",
        "  print('====================')\n",
        "  accuracy = accuracy_score(testy, predictions)\n",
        "  print('Accuracy: %.3f' % accuracy)\n",
        "  recall = recall_score(testy, predictions)\n",
        "  print('Recall: %.3f' % recall)\n",
        "  precision = precision_score(testy, predictions)\n",
        "  print('Precision: %.3f' % precision)\n",
        "  f1 = f1_score(testy, predictions)\n",
        "  print('F1: %.3f' % f1)\n",
        "  print('====================')\n",
        "\n",
        "#Function to plot ROC Curve\n",
        "def plot_roc(testy, predictions, title):\n",
        "    fpr, tpr, thresholds = roc_curve(testy, predictions)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print('AUROC: %.3f' % roc_auc)\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], '--')\n",
        "    plt.xlim([0.0, 1.05])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "#Function to plot PR Curve\n",
        "def plot_prc(testy, predictions, title):\n",
        "    precision, recall, thresholds = precision_recall_curve(testy, predictions)\n",
        "    auc_score = auc(recall, precision)\n",
        "    plt.plot(recall,precision, label='PR curve (area = %0.2f)' % auc_score)\n",
        "    plt.plot([0, 1], [0.5, 0.5], linestyle='--' )\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.xlim([0, 1.02])\n",
        "    plt.ylim([0, 1.02])\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "#Function to plot precision and recall vs all tresholds\n",
        "def plot_prec_recall_vs_thresh(testy, predictions, title):\n",
        "    precision, recall, thresholds = precision_recall_curve(testy, predictions)\n",
        "    plt.plot(thresholds, precision[:-1], 'b--', label='precision')\n",
        "    plt.plot(thresholds, recall[:-1], 'g--', label = 'recall')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PGn4NJLzLf5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "Tqr1J9Xj900l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset which will be using in this demo is the UCI Breast Cancer Wisconsin (Diagnostic) Data Set: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
        "\n",
        "\n",
        "Here, researchers obtained Fine Needle Aspirate (FNA) of breast mass and generated it’s digitized images. The Dataset contains instances describing the characteristics of the cell nuclei in those images. Every instance is marked with either of the two diagnosis: ‘M’ (Malignant) or ‘Benign’). Our Task is to train a Neural Network on this data to diagnose Breast Cancer given the characteristics mentioned above."
      ],
      "metadata": {
        "id": "ZH9cplaK93e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribute Information:\n",
        "\n",
        "1) ID number\n",
        "\n",
        "2) Diagnosis (M = malignant, B = benign)\n",
        "\n",
        "3-32)\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "a) radius (mean of distances from center to points on the perimeter)\n",
        "\n",
        "b) texture (standard deviation of gray-scale values)\n",
        "\n",
        "c) perimeter\n",
        "\n",
        "d) area\n",
        "\n",
        "e) smoothness (local variation in radius lengths)\n",
        "\n",
        "f) compactness (perimeter^2 / area - 1.0)\n",
        "\n",
        "g) concavity (severity of concave portions of the contour)\n",
        "\n",
        "h) concave points (number of concave portions of the contour)\n",
        "\n",
        "i) symmetry\n",
        "\n",
        "j) fractal dimension (\"coastline approximation\" - 1)"
      ],
      "metadata": {
        "id": "TPvQSUrt-YvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the dataset using pandas"
      ],
      "metadata": {
        "id": "CXduS7kS-gat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_file = \"/content/drive/MyDrive/Work/HIDS_506_2022/lecture6_draft/data/breast_cancer.csv\""
      ],
      "metadata": {
        "id": "FDEbErXD90Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df = pd.read_csv(breast_cancer_file)"
      ],
      "metadata": {
        "id": "h6P0dli3-_ci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "101a27d7-09e1-4a8d-b193-3108ece75ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-be7837c710a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbreast_cancer_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreast_cancer_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Work/HIDS_506_2022/lecture6_draft/data/breast_cancer.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df.shape"
      ],
      "metadata": {
        "id": "OqvOFgpM-_aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df.head()"
      ],
      "metadata": {
        "id": "C_vIhkTv_471"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features and Outcome"
      ],
      "metadata": {
        "id": "lTyBZdnU_8Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df.columns"
      ],
      "metadata": {
        "id": "iIYKkd78_7or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the diagnosis (outcome)"
      ],
      "metadata": {
        "id": "TCPNPj-eAG09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df['diagnosis']"
      ],
      "metadata": {
        "id": "GTfVjkI_AJnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(breast_cancer_df['diagnosis'])"
      ],
      "metadata": {
        "id": "3ymA2O0JAUzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert the outcome values to 1 (for M: Malignant) and 0 (for B: Benign)"
      ],
      "metadata": {
        "id": "CI1ICvy6AWs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df['diagnosis'].replace(('M','B'),(1,0), inplace = True)"
      ],
      "metadata": {
        "id": "7OAss_b4AgKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the dataset into feature matrix (X) and outcome (y)**"
      ],
      "metadata": {
        "id": "ypW7d_NeBPWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_df = breast_cancer_df['diagnosis']\n",
        "X_df = breast_cancer_df.drop(columns=[\"diagnosis\",\"id\"])"
      ],
      "metadata": {
        "id": "-DckRQZCBfZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_df)"
      ],
      "metadata": {
        "id": "67D2fYWOB6B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.shape"
      ],
      "metadata": {
        "id": "xFEeWm7zB8de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check some statistics about the features"
      ],
      "metadata": {
        "id": "0tgru_ndAw4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df.describe()"
      ],
      "metadata": {
        "id": "71b8RPQ9AwL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need for scaling as different features have different ranges. More about this later."
      ],
      "metadata": {
        "id": "kI6V4NbpA-V3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and test split**"
      ],
      "metadata": {
        "id": "ZSrCDbC0C9Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "KttfF2nyDE1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "08OjSJYrDBrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_train), Counter(y_test)"
      ],
      "metadata": {
        "id": "IoioQQkeDzVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.describe()"
      ],
      "metadata": {
        "id": "zPIxBAn8D313"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**\n",
        "\n",
        "We will use sklearn `StandardScaler()` function to fit the scaler and transform the training and test.\n",
        "\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n"
      ],
      "metadata": {
        "id": "YzH18j1BD_KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "sJdLN4w5EQ6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "JR7rNCcgEnKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important fit on only training data\n",
        "\n",
        "Short reason: General principle: any thing you learn, must be learned from the model's training data.\n",
        "\n",
        "Nice article: https://sebastianraschka.com/faq/docs/scale-training-test.html"
      ],
      "metadata": {
        "id": "TQ8D9LBeEq2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(X_train)"
      ],
      "metadata": {
        "id": "S1vJiTFJEqFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual scaling: Transforming train and test"
      ],
      "metadata": {
        "id": "RxEe6KdSExX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now apply the transformations to the data:\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "qN8yLhUjE08S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "ZL7SuvsxFAWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test Neural Network using sklearn"
      ],
      "metadata": {
        "id": "ctZfQ0V-FsA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will `MLPClassifier()`, which is an implementation of neural network in sklearn and helps users to define a neural network architecture.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
      ],
      "metadata": {
        "id": "iXUKeTxTJwFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "chimjNymKcO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(32,16), max_iter=500)"
      ],
      "metadata": {
        "id": "PGrzBJ8TFxN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit"
      ],
      "metadata": {
        "id": "s3t18u23KoSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "3RozDkhQKfsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "Q2eCFZLlKpAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "78DHh17XKlh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print classification report"
      ],
      "metadata": {
        "id": "7IE2ut1nKuud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ZoDx-ct1KuLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some other evaluation metrics"
      ],
      "metadata": {
        "id": "EQlHjOHFK17P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "f-rnfHWhK7fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "t2efACqrK3-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "id": "hn_3wyrgLD99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cm, show_absolute = True, show_normed = True)"
      ],
      "metadata": {
        "id": "FOIa6nYtLFLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get prediction probabilities to plot ROC and precision vs. recall"
      ],
      "metadata": {
        "id": "hEDNg7IFLmai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = mlp.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "kZxJ_u7XL0V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot ROC Curve"
      ],
      "metadata": {
        "id": "Pu8QZLWuLaVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc(y_test, y_pred_prob, 'ROC')"
      ],
      "metadata": {
        "id": "xWepSZZqLMwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot PR Curve"
      ],
      "metadata": {
        "id": "7X8GXmIHMPEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prc(y_test, y_pred_prob, 'PRC')"
      ],
      "metadata": {
        "id": "g5suX0hdL-3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot precision and recall vs all thresholds"
      ],
      "metadata": {
        "id": "0rcYxk9aMRh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prec_recall_vs_thresh(y_test, y_pred_prob, 'PRvThresh')"
      ],
      "metadata": {
        "id": "jmxiaq8HMMFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network using Keras"
      ],
      "metadata": {
        "id": "9YsD4bW9MVU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a popular package for deep learning Keras with TensorFlow backend\n",
        "\n",
        "Learn more about Keras: https://keras.io/"
      ],
      "metadata": {
        "id": "2cq2_sOYNMWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "A1EIXDl_NPq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "from keras.callbacks import TensorBoard"
      ],
      "metadata": {
        "id": "uAldbX6FMYsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "9WVydAhjNnhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many variants of deep neural networks.\n",
        "\n",
        "We will start from the simplest one, feedforward neural network, which is similar to the neural network architecture shown in the following figure.\n",
        "\n",
        "![nn](https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png)\n",
        "\n",
        "[Source] https://medium.com/@curiousily/tensorflow-for-hackers-part-iv-neural-network-from-scratch-1a4f504dfa8\n",
        "\n",
        "In our first neural network model, we will construct the one that\n",
        "\n",
        "- take the input and pass them into the 32-dimension first hidden layer,\n",
        "- take the output of the first layer and pass them into the  16-dimension second layer,\n",
        "- take the output of the second layer and pass them into the last layer for prediction,\n",
        "- the output of the last layer is the prediction.\n",
        "\n",
        "One more hidden layer than the above figure.\n",
        "\n",
        "In keras, we use `Sequential()` as the skeleton of the neural network model, and sequentially add the layer on it.\n",
        "After building the layers, we need to compile the model and defined the optimizer, loss function and evaluation metrics to optimize our model.\n",
        "In this example, we use the optimizer called `adam`, to minimize the value of loss function `binary_crossentropy` (if you work on the regression problem, remember to change to `mse`), and judge by accuracy."
      ],
      "metadata": {
        "id": "1w-8BPRnORE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Initialize the Neural Network**"
      ],
      "metadata": {
        "id": "H96b8Mc5Nr3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Sequential()"
      ],
      "metadata": {
        "id": "6jLHI4i7N7pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Define the architecture**"
      ],
      "metadata": {
        "id": "QIkvb0xIO66E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first hidden layer for input data\n",
        "clf.add(Dense(units=32,\n",
        "              kernel_initializer='uniform',\n",
        "              activation='relu',\n",
        "              input_dim=X_train.shape[1]))"
      ],
      "metadata": {
        "id": "W_RC0n2uOslo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# second hidden layer\n",
        "clf.add(Dense(units=8,\n",
        "              kernel_initializer='uniform',\n",
        "              activation='relu'))"
      ],
      "metadata": {
        "id": "VlbrSweDO6Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding dropout to prevent overfitting\n",
        "dropout = 0.3\n",
        "clf.add(Dropout(dropout))"
      ],
      "metadata": {
        "id": "9KLBwQyESDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the last  layer for output\n",
        "clf.add(Dense(units=1,\n",
        "              kernel_initializer='uniform',\n",
        "              activation='sigmoid'))"
      ],
      "metadata": {
        "id": "PZFz6UUlO9pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Compile/build the network**"
      ],
      "metadata": {
        "id": "jmMT1_zRPCyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.compile(optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CD9CdVkuPHHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the architecture"
      ],
      "metadata": {
        "id": "ab4bPUPnPLr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.summary()"
      ],
      "metadata": {
        "id": "ZTTH2HLuPNob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better visualization"
      ],
      "metadata": {
        "id": "AkbioFfnPUy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "2_eITo0VPchy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(clf, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "3ZPye_xtPe2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Train the model**"
      ],
      "metadata": {
        "id": "TWU44fd_PrU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not required just to visualize the training"
      ],
      "metadata": {
        "id": "00ux0pgoQDDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "HZHaWfoDPtk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "MW6A9PVeQKuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = clf.fit(X_train,\n",
        "                  y_train,\n",
        "                  validation_split = 0.2,\n",
        "                  batch_size = BATCH_SIZE,\n",
        "                  epochs = EPOCHS,\n",
        "                  callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "V9H-Ei_YQUgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Loss using Tensor board"
      ],
      "metadata": {
        "id": "lrSOrw-eQ8OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "rA_84wHxRBEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "RuT9-VsBRSiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "75KuTZ42RUu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions and test"
      ],
      "metadata": {
        "id": "khY03trISh-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred_prob = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "OV5Kcm9uSgbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob[:5]"
      ],
      "metadata": {
        "id": "BohR7zLxUizX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (clf.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "id": "5dzqb427SxLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:5]"
      ],
      "metadata": {
        "id": "CFrTdIbhT50M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation metrics"
      ],
      "metadata": {
        "id": "H3bg1i6wS70N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred),\n",
        "                      show_absolute = True,\n",
        "                      show_normed = True)"
      ],
      "metadata": {
        "id": "RwZK4U0LTDdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "xDj14-HiS1Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make network robust and prevent overfitting?\n",
        "\n",
        "Use Dropout layer: https://keras.io/api/layers/regularization_layers/dropout/"
      ],
      "metadata": {
        "id": "N-SUYnCwTSOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The END** <br>\n",
        "**Authors: Dr. Samir Gupta, Dr. Matthew McCoy & ICBI AIM-AHEAD Team**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ICBI/AIMAHEAD_GU_publicCourseData/main/HIDSLOGO.AA1.jpg\" alt=\"Powered by\" width=\"500\"/>"
      ],
      "metadata": {
        "id": "b6OvdwWTIW4M"
      }
    }
  ]
}