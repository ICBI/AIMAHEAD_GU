{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICBI/AIMAHEAD_GU/blob/main/Courses/ML_Concepts/Module_01_Introduction_to_Classification/Module_01_Introduction_to_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ICBI/AIMAHEAD_GU_publicCourseData/main/icbi-aimahead-hids.png\" alt=\"Powered by\" width=\"600\"/>"
      ],
      "metadata": {
        "id": "X-78aC6o_Ehe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVAqdOpiH6In"
      },
      "source": [
        "#Module 1: Introduction to Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okA-YCqEIB16"
      },
      "source": [
        "The aim of this notebook is to provide an hands-on demo to machine learning in Python. We will be using `scikit-learn`, which is a popular Python package for machine learning. `Scikit-learn` is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities. \n",
        "\n",
        "Learn more about **scikit-learn** (**sklearn** for short) here: https://scikit-learn.org/stable/\n",
        "Sklearn tutorials covering various aspects of machine learning can be found here: https://scikit-learn.org/stable/tutorial/index.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AyVFGr1JJQ-"
      },
      "source": [
        "The learning objective of this notebook are:\n",
        "* Learning how to train a basic classification model\n",
        "* Use the model to make predictions on new unseen data\n",
        "* Generate a confusion matrix and a classification report \n",
        "* Learn how to calculate different metrics\n",
        "* Plot ROC curves\n",
        "* Try other classifiers and compare models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1rH9XxJepN"
      },
      "source": [
        "## Packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JGd4hITJna_"
      },
      "source": [
        "We will start by loading some of the packages that will help us \n",
        "organize and visualize the data. Other packages will be loaded as necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUsd9_ZNI49l"
      },
      "source": [
        "#Import packages\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections, numpy\n",
        "import mlxtend\n",
        "import matplotlib \n",
        "from matplotlib import pyplot \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "matplotlib.rcParams['figure.figsize'] = (10, 10)\n",
        "\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy1I1m_zUT5u"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY5DqwrDUV1z"
      },
      "source": [
        "We will be building and evaluating models to predict **diabetes** using using the diabetes dataset from the National Institute of Diabetes and Digestive and Kidney Diseases (**NIDDK**). \n",
        "\n",
        "The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. \n",
        "\n",
        "We will be using the **NIDDK diabetes dataset**, which contains 768 female patients of at least 21 years old.  Fields in this dataset are:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **Pregnancies:** Number of times pregnant\n",
        "* **Glucose:** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "* **BloodPressure:** Diastolic blood pressure (mm Hg)\n",
        "* **SkinThickness:** Triceps skin fold thickness (mm)\n",
        "* **Insulin:** 2-Hour serum insulin (mu U/ml)\n",
        "* **BMI:** Body mass index (weight in kg/(height in m)^2)\n",
        "* **DiabetesPedigreeFunction:** Diabetes pedigree function\n",
        "* **Age:** Age (years)\n",
        "* **Outcome:** Class variable (0 or 1); class value 1 is interpreted as \"tested positive for diabetes\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od2TS_dSVuT6"
      },
      "source": [
        "Let's explore the dataset. You must first obtain the data file \"diabetes.csv\" and upload it to a directory that is accessable by this colab notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyeIA6tKVpeo"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ICBI/AIMAHEAD_GU_publicCourseData/main/ML_Concepts/diabetes.csv\n",
        "diabetes_file = \"/content/diabetes.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df = pd.read_csv(diabetes_file)"
      ],
      "metadata": {
        "id": "q7CZ8tDU8YmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the head() function to inspect the first few rows of the dataset, and the \"shape\" property confirms that we have 9 columns of data on 768 patients."
      ],
      "metadata": {
        "id": "lZ6LzBpSeX2Q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPgy2AMLV8Lv"
      },
      "source": [
        "diabetes_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V4S1m1IV9BT"
      },
      "source": [
        "diabetes_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc_ZITvoV_Rd"
      },
      "source": [
        "A common problem with large datasets is missing values. We can quantify how many of patients are missing some data by using the \"isnull()\" and \"sum()\" methods to generate a count of missing values, broken down by the fields in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6BNAC4TWBkx"
      },
      "source": [
        "diabetes_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The missing values in the \"Pregnancies\" field actually correspond to the patient never having given birth. There is a convient function for replacing missing values called \"fillna()\". The first argument is the value used to replace the missing data, and the \"inplace=True\" option modifies the dataframe without having to reassign. Here, we can replace the missing pregnacy data with a 0."
      ],
      "metadata": {
        "id": "Wdp0aFHPeFBL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5XrWXu3WDKb"
      },
      "source": [
        "diabetes_df['Pregnancies'].fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3qFqo0jWDsy"
      },
      "source": [
        "Similarly, we can use the \"fillna()\" method to replacing the other missing values in the dataset. We can select any value that makes sense for the given field, and in this case we use the median value to replace the missing data from the corresponding column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjcsmzy_WI9c"
      },
      "source": [
        "diabetes_df['Glucose'].fillna(diabetes_df['Glucose'].median(), inplace=True)\n",
        "diabetes_df['BloodPressure'].fillna(diabetes_df['BloodPressure'].median(), inplace=True)\n",
        "diabetes_df['SkinThickness'].fillna(diabetes_df['SkinThickness'].median(), inplace=True)\n",
        "diabetes_df['Insulin'].fillna(diabetes_df['Insulin'].median(), inplace=True)\n",
        "diabetes_df['BMI'].fillna(diabetes_df['BMI'].median(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can verify that all missing data has been replaced using the \"isnull()\" and \"sum()\" methods in series."
      ],
      "metadata": {
        "id": "OOiU_4CzfxWU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX9zgsO_WKjN"
      },
      "source": [
        "diabetes_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that all the missing values have now been replaced. Using Counter(), we can summarize the \"Outcome\" column of our dataframe. "
      ],
      "metadata": {
        "id": "GW4reJA9sdCJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN2z3m_0WMet"
      },
      "source": [
        "Counter(diabetes_df['Outcome'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQiyKwPWWY1t"
      },
      "source": [
        "We can see that there are 500 patients without a diabetes diagnosis, and 268 who do have diabetes. But before we can train ML models, we have to seperate the features (`X`) and the outcome variable (`y`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5dUxRcNWlhd"
      },
      "source": [
        "![samples-features.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To separate our features from the outcome label, we can use the drop() method to remove the \"Outcome\" column from the dataframe, and reassign the result to X_df. For the outcome label, we can simply assign the \"Outcome\" column to a new dataframe."
      ],
      "metadata": {
        "id": "b8H6Oy1htfGB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcWVRHLRWNfT"
      },
      "source": [
        "#Preparing the data for the ML models\n",
        "X_df = diabetes_df.drop('Outcome',axis=1)\n",
        "y_df = diabetes_df['Outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the shape() and head() methods, we can varify that X_df and y_df are what we expect. The data for all 768 patients has been separated in the 8 feature columns and 1 label column."
      ],
      "metadata": {
        "id": "oqQkTpf8t7PS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vja-bk1_WtQU"
      },
      "source": [
        "X_df.shape, y_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgzZ1zw8WwqP"
      },
      "source": [
        "X_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTb4p4GRWygI"
      },
      "source": [
        "y_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTiHZnCzW1PO"
      },
      "source": [
        "To begin, let's build models on a subset of `X` (say 2 features). This will make visualization easier. We can subset the feature data frame by a list of columns, in this case, \"Glucose and \"Age\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_rq_xgrWz_C"
      },
      "source": [
        "X_subset_df = X_df[['Glucose', 'Age']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lnnb0aqXSdi"
      },
      "source": [
        "Here we build a simple function to visualize a 2D dataset and color the points by the outcome label. The function takes in 3 variables; the features (X_df), the labels (y), and the plot title (title) which is set to \"Data in 2D\" by default. The function returns the fi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs0Wtk3SXo_9"
      },
      "source": [
        "def visualize_2d(X_df,y, title=\"Data in 2D\"):\n",
        "  X = X_df.to_numpy()\n",
        "  fig, ax = plt.subplots(figsize=(10,10))\n",
        "  sns.scatterplot(x=X[:,0],y=X[:,1],hue=y,ax=ax);\n",
        "  ax.set_title(title)\n",
        "  ax.set_xlabel(\"x1\")\n",
        "  ax.set_ylabel(\"x2\")\n",
        "  plt.close()\n",
        "  fig.show()\n",
        "  return fig, ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the feature and label dataframes to our subset of data, we can visualize the relationship between Glucose on the x-axis with age on the y-axis. "
      ],
      "metadata": {
        "id": "fSYlQViYvzn1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIOVhlV4XEa2"
      },
      "source": [
        "fig, ax = visualize_2d(X_subset_df, y_df);\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nXjM50EX-LK"
      },
      "source": [
        "There seems to be a relationship between these 2 vairables and diabetes, where it seems more likely that increasing age and glucose levels are associated with diabetes. \n",
        "\n",
        "Let's fit a **Logistic Regression** model on this 2d data. Logistic Regression is a basic **classification model** that uses a logistic function to model a binary dependent variable. Sklearn's documentation for Logistic Regression can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "There is a number of ML classifiers in sklearn. They differ based on the particular algorithm each classifier employs to train the feature weights, but can be trained in a standard way. Firse we define a model object, then use the fit() methods with our feature and label dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0y8_W6EX7NU"
      },
      "source": [
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_subset_df, y_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMIzeE4VZ6kZ"
      },
      "source": [
        "One of the outputs of the model is a decision function. A simple way of thinking of this function is as an equation that predicts the outcome from the input variables. In this case, we have 2 input variables, so the decision function can be visualized as a line. If a new patient's glucose and age inputs fall above this line, the prediction is that they have diabeties.\n",
        "\n",
        "Here, we define a funtion to visualize the decision boundary of the 2-d model by plotting the decision boundary on the same plot as our datapoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRXHV1oiZ99G"
      },
      "source": [
        "def plot_decision_boundary(model, ax=None):\n",
        "  xlim = ax.get_xlim()\n",
        "  ylim = ax.get_ylim()\n",
        "\n",
        "  # create grid to evaluate model\n",
        "  x = np.linspace(xlim[0], xlim[1], 30)\n",
        "  y = np.linspace(ylim[0], ylim[1], 30)\n",
        "  Y, X = np.meshgrid(y, x)\n",
        "  xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "  P = model.decision_function(xy).reshape(X.shape)\n",
        "\n",
        "  # plot decision boundary \n",
        "  ax.contour(X, Y, P, colors='k',\n",
        "            levels=[0], alpha=0.5,\n",
        "            linestyles=['-'])\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_ylim(ylim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can plot the dicision boundary of our 2D regression model."
      ],
      "metadata": {
        "id": "bJtOHt85DUaO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4RNxEFiaDVs"
      },
      "source": [
        "plot_decision_boundary(lr_model,ax)\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI9ah4E_aL1a"
      },
      "source": [
        "We can see that the model does an OK job separating out those with diabetes from those without. However there are a number of cases that fall on the \"wrong\" side of the line, which would result in a false positive or false negative prediction.\n",
        "\n",
        "Question: what is this decision boundry in Logistic Regression?\n",
        "\n",
        "Answer: The model decision function for 2 variable is: y = w1\\*x1 + w2\\*x2 + c, which defines a line. The coeficients w1 and w2, and intercetp can be extracted using methods provided with the mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrY8a4wyaMZO"
      },
      "source": [
        "lr_model.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp6hnlocaS45"
      },
      "source": [
        "lr_model.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc_Vq2jZaWoH"
      },
      "source": [
        "## Train and Test Sets: Splitting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsS270vviqaz"
      },
      "source": [
        "A machine learning model aims to make good predictions on new, previously unseen data. But if you are building a model from your data set, how would you get the previously unseen data? Well, one way is to divide your data set into two subsets:\n",
        "\n",
        "* **training set** — a subset to train a model.\n",
        "* **test set** — a subset to test the model.\n",
        "\n",
        "Good performance on the test set is a useful indicator of good performance on the new data in general, assuming that:\n",
        "\n",
        "* The test set is large enough.\n",
        "* You don't cheat by using the same test set over and over.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nNbLHbFjQn_"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl__3uTUjl7I"
      },
      "source": [
        "**Never train on test data**. If you are seeing surprisingly good results on your evaluation metrics, it might be a sign that you are accidentally training on the test set. For example, high accuracy might indicate that test data has leaked into the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wLvt3tLjo9b"
      },
      "source": [
        "The sklearn library provides the function `train_test_split` to split your data into train and test sets. The train_test_split() funtion will take the input features (X_df) and associated labels (y_df) and return a randomized split of the data. The size of the test set is defined as a percentage of this entire set by the \"test_size\" variable. I this case, we split 20% of our dataset into the test set, and will train on the remaining 80% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDsWcOwMaapP"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can verify the size of our training and test sets using the shape and head methods."
      ],
      "metadata": {
        "id": "RUGTzyjTEzZm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h4BxBgLj1BB"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq0Gi7L7j1qR"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7dVGzTij8Hu"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce63ajgPj5j_"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG5r9muFj-b4"
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see how many of each class we have using the Counter() funtion. The training dataset has 223 diabetes patients and the test set has 45."
      ],
      "metadata": {
        "id": "bUUt0Ku0FDPJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fbyd16tkZUn"
      },
      "source": [
        "Counter(y_train), Counter(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_DbxJy1kMmT"
      },
      "source": [
        "## Train and test classification models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF3JGgtukRY1"
      },
      "source": [
        "In this step we train a model on the data and generate predictions. To make predictions we use the scikit-learn function \"predict\" and that takes as input, data in the same format as the training set.\n",
        "\n",
        "Here, we will train the ML model on all 8 features and not just 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seo-RoYVkfuC"
      },
      "source": [
        "Fit/train a model on the training dataset by first defining an sklearn model object, and then calling the fit() method with our training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1japyYNkAL8"
      },
      "source": [
        "#Fit the model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCWz3-dIkder"
      },
      "source": [
        "We can use the predict() method on the trained model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa25BA9jkb9J"
      },
      "source": [
        "#Generate Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNlPx-ACklBR"
      },
      "source": [
        "Every ML classifier outputs a set of numbers for each data point that represents the **probabilty** of classifying that point as a zero (no diabetes) or 1 (diabetes). This data can be found by calling the predict_proba() method on the test set. The method returns an array for each patient in the test set, where the first entry is the probability of not having diabetes and the second is the probabiltiy of having diabetes. As we will see below, this is useful when appying different probability thresholds to making a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9VOqlvHk1AM"
      },
      "source": [
        "y_pred_prob = model.predict_proba(X_test)\n",
        "y_pred_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can plot the probability of having diabeties as a histogram to visualize the prediction results."
      ],
      "metadata": {
        "id": "QD424OxqGy--"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpmUeyXYk6pv"
      },
      "source": [
        "plt.hist(y_pred_prob[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLuVCTvmlQau"
      },
      "source": [
        "## Evaluation the classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxXun1w2ldtR"
      },
      "source": [
        "After training the classification model on the training set and generating predictions on the test set, we would like to quality of the predictions i.e. the performance of the trained classification model on new test set. This is done using standard classification evaluation metrics such as **accuracy, precision and recall**. These require the list of predictions of your model and the actual labels/outcomes (ground truths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8odn1O87mvrj"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqecZho4m01S"
      },
      "source": [
        "We calculate the confusion matrix to evaluate performance of our model. We then review and caclulate the different metrics. \n",
        "\n",
        "A confusion matrix is a cross-tabulation that shows the correct class (or label) for each datapoint that was tested, along with the predicted class. You can use this 2-way table to determine if your model is making Type 1 (False Positve) or Type 2 (False Negative) errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bohAqAAGmG91"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf_jrN2um6dy"
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matriz is a way to visualize how many predictions were correct. That is, the predicted diagnosis on the test set matched the prediction. We can see that 95 patients were correctly predicted to not have diabetes and 23 patients were correctly predicted to have diabetes. However, there were 14 patients where the model predicted them to have diabetes when they did not, and 22 patients that had diabetes were incorrecly diagnosed as being health."
      ],
      "metadata": {
        "id": "rFrDqqTFHEqR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzNpgq8tm7WS"
      },
      "source": [
        "plot_confusion_matrix(conf_mat=cm, show_absolute=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2enMaOUSnDho"
      },
      "source": [
        "### Types of Errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpA-oR0PnJMe"
      },
      "source": [
        "When making a prediction for a two-class classification problem, the following types of prediction vs actual can be made by a classifier:\n",
        "\n",
        "* **False Positive (FP):** predict an event when there was no event.\n",
        "* **False Negative (FN):** predict no event when in fact there was an event.\n",
        "* **True Positive (TP):** predict an event when there was an event.\n",
        "* **True Negative (TN):** predict no event when in fact there was no event.\n",
        "\n",
        "Remember\n",
        "\n",
        "* Type I Error  = False Positive  (Predicted 1, Actual 0)\n",
        "* Type II Error = False Negative: (Predicted 0, Actual 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwcw0S0pnKBD"
      },
      "source": [
        "#We use the confusion matrix function to extract the different types of errors\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "tn, fp, fn, tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqkHHwfRnUOw"
      },
      "source": [
        "### Compute different evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BspzDPjQnYP8"
      },
      "source": [
        "We can quantify error in different ways to get a sense of how well the model is performing. In this section we will  use builtin scikit-learn scoring functions and the types of errors derived from the confusion matrix functions to evaluate our classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFaxWtwLnX5y"
      },
      "source": [
        "#Accuracy \n",
        "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "print('Accuracy: %.3f' % accuracy)\n",
        "\n",
        "#Recall/Sensitivity/True Positive rate\n",
        "recall = sensitivity = tpr = tp / (tp + fn)\n",
        "print('Recall: %.3f' % recall)\n",
        "\n",
        "#Precision\n",
        "precision = tp / (tp + fp)\n",
        "print('Precision: %.3f' % precision)\n",
        "\n",
        "#Specificity/Negative Recall/ True negative Rate/ 1-False Positive Rate\n",
        "specificity = tn / (tn + fp)\n",
        "print('Specificity: %.3f' % specificity)\n",
        "\n",
        "#F1 Score\n",
        "f1 = 2*(precision*recall)/(precision+recall)\n",
        "print('F1: %.3f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smpysDpNnpnl"
      },
      "source": [
        "#Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: %.3f' % accuracy)\n",
        "\n",
        "#Recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %.3f' % recall)\n",
        "\n",
        "#Precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %.3f' % precision)\n",
        "\n",
        "#The f1-score is the harmonic mean of precision and recall\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1: %.3f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function that take actual labels and predictions as input and prints the classification metrics. Same as before just encapsulated in a function so that we can call it with different inputs"
      ],
      "metadata": {
        "id": "U9Y4dxGH092E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function that calculates and print metrics\n",
        "def show_metrics(y_test, y_pred):\n",
        "  print('====================')\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print('Accuracy: %.3f' % accuracy)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  print('Recall: %.3f' % recall)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  print('Precision: %.3f' % precision)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  print('F1: %.3f' % f1)\n",
        "  print('====================')"
      ],
      "metadata": {
        "id": "321uiGeY072X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_metrics(y_test, y_pred)"
      ],
      "metadata": {
        "id": "qNYBS6Pw1JbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics with different threshold**"
      ],
      "metadata": {
        "id": "VIYIdOkC1MsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the prediction probablility to alter the threshold where a predicion is made. Initially, we can use a threshold of 50% (threshold=0.5) to predict a diabetes diagnosis when the prediction probability is greater than 50%."
      ],
      "metadata": {
        "id": "qMobT3wLH_IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function that returns predictions at a specific threshold\n",
        "def get_predictions(y_pred_prob, threshold=0.5):\n",
        "  predictions = np.where(y_pred_prob <= threshold, 0, 1)\n",
        "  return predictions[:,1]"
      ],
      "metadata": {
        "id": "Q_QMq6va1QFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increase the threshold**\n",
        "\n",
        "We can be more strict, and apply a higher prediction threshold. When we increase the threshold to 70% there is a change in the model performance. The number of false positives decreases, but false negatives increase. As a result, precision increases, while recall decreases:"
      ],
      "metadata": {
        "id": "-Ld6d4MY1bhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = get_predictions(y_pred_prob, 0.7)\n",
        "show_metrics(y_test, y_pred1)"
      ],
      "metadata": {
        "id": "BoX4QoEu1aRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decrease the threshold**\n",
        "Similarly, a decrease in the threshold also changes the performance. False positives increase, and false negatives decrease. As a result, this time, precision decreases and recall increases:\n"
      ],
      "metadata": {
        "id": "uEtxJF_a2U8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = get_predictions(y_pred_prob, 0.3)\n",
        "show_metrics(y_test, y_pred2)"
      ],
      "metadata": {
        "id": "FfhODtXt2ele"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVqmTOlWn_PP"
      },
      "source": [
        "#### Threshold independent Metric: **AUC-ROC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-iTgIZJoRV_"
      },
      "source": [
        "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
        "\n",
        "* True Positive Rate\n",
        "* False Positive Rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVINxPMOoYlv"
      },
      "source": [
        "An ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXIAAAEVCAYAAAD91W7rAAAgAElEQVR4nO3d+1tUV54u8PoX7Ng50jPTlzOTJ/3MMck50z7NyWROznS6ndM9PSenxxnLXCak07anczkJMaYS0STGK+ANL2h5D8rFu4CoWIoheGlvgIhcpQARkDsCIogI7/nBZ5W7NlVUUbWr1t673s/zfJ+WYl9WpTcvi1V7rW0BEREZmkV2A4iIKDgMciIig2OQExEZHIOciMjgGORERAbHICciMjgGORGRwTHIiYgMjkFORGRwDHIiIoNjkBMRGRyDnIjI4BjkREQGxyAnIjI4BjkRkcExyImIDI5BTkRkcAxyIiKDY5ATERkcg5yIyOAY5EREBqfLIC8tLUV+fj7y8/PR2dkpuzlERLqmyyBfuHAhXnnlFbzyyiu4ePGi7OYQUQi09wyj4vYgzt7ow5EL3die246EA3cwb3sD3l5Ti5TTHT6PMTg0GoaW6h+DnIgC1tz1EGW3BtDYMeRz29QzHYj+uAz/+Z1rmDSz0GfN297g85gM8sdCFuQ2my3gfRnkRHKV3RrA7rwOxO9vxrztDfhDUi1+t6QaL9vKMfXd6/jBm8Vuobt8X7PPY9qPt/kV4KL+uK4uDO/UHIIK8qioKFgsFq8VKAY5kXYGhkZQ2TiIMyW92HWqHeUNAz73mbv11oRC17bTd+85I78Tf/lWMf7Ln67j7z8pwz9/VYVZ8TX4vxvqYNvZgBX7m7EhuxW78zqQdbHbr3bSY0EFud1uh8Ph8Pg99siJwqOm+QEOnuvC5mNtWJzehA821cO6oga/+LwCP/792GGMbbltPo+5fF+zXwH+N7NL8PPYMiQcuBOGd0recIycyOBWHrwzod6zP8Mgl6v7Eb+/GQkH7mDzsTbsK+hE3rVeXL3Zj9qWB7h771EY3hn5i0FOpBO32oaQc/kulu5tgnVFDV74oBQrD/ru6e4v6PIa2s/MLsGLc8vwL4uqEbPaiU+2NeBkYU8Y3g2FE4OcSJJbbUPYfKwN/7r0Jn70tuc7Od5a5fR5nGLnffwhqRZL9zYh9UwHzpff8+suEjIPBjlRGN1uH8Ki1Eb8/Sdlfg2D/N2HN2Q3mQyAQU4URoU1/eMG98u2cnxkv4UdJ9txubofvfc5Fk2+MciJwuyZ2SWYNLMQP4wpxqz4GiTntKLYeV92s8jAGOREGjl0vsuv7Y5fuYurN/vdXuvu7kZ2Viba29tD0TQyOQY5URAaO4awOL0Jz8553Ms+fuVuQMdpaGjAp3PfR/yyBVi3NhHnzp3FwAAnxJB/GOREE/RoBDh66S7+bdnNMWPcbyT6vsvEm1UrV6D5pgMNFSdwOGMDFsZ9gh3bN+PatWsatp7MiEFO5KeBoRFsymnF1Heve/yg8r/9vxvYnhv40Mj58+dxOGMj0FfoqrIrh7FnxyrY5n2EfXvTUFNTo+E7IrNgkBP50Hv/ERIO3PG4at/TrxdhdlItzt7oC/o8jx49gm3eR25BLmq4+zIu5adh07plWLxoAY4dy0Fra6sG747MgEFO5IOnHvhfvVWMr9Oa0HZ3WNNzZWSk4kpBhscwF3W38TvkHduBxBVfYO3qBBQUFKC/v9/3wcm0GOREPiQceLKWyU/nXMe6rBbcGxwJybnq6+uxfs3icYNcWbcrc5G1fxO+XPgptm3dhKKiopC0i/SNQU7kQ/e9R/iHT8uxO8/3E2u0kBi/BC01p/wOc1GVhUeQtmst5n3yITIy0lBdXR2W9pJ8DHIinTl7tgCZezdOOMhFjfRcwdWCDNg3rMCiL+OQk3MUzc2+Vzwk42KQU8Tq7B3Gl3sa0a2zJVmHhoYw/7PYgINcWb3NZ/HtiV1Ynfg1Vq1cgfz8fPT1Bf/BLOkLg5wizvW6+5izvg5T3ijCpJmFWJzeJLtJY6TuSUHR+X2ahLmo5moHjh60Y9GXn8Fu34SrV69idJTPvDQDBjlFjNPXevGbL6vG3IHyo7f1N+HG6XRi07qlmga5sqqLs5Cxez3mffIh0tJSUVFRIfstUxAY5GR6GfmdiP7Y87KxH9lvobnrYVja0draivPnzyM7OxuHDx/G3r17x63PbB+jqyE/ZGEuqvDcPmzbvBJfLpyPo0eP+myX0Ss7Oxu5ubm4du0aHj4Mz//3ocYgJ1MSszCfe6/UY4C/u7EelY2DYWlLZWUltm3djMQVi+A4moL83BQUnduLKwXp41bZlcMhD3Fl9becx5WCDJ/tMnoVnt0LR84u7E+zY2HcZzh06CAGB8NzLYQKg5xM6beLxg6hTHmjCLadDWF9es6BA/uwbfNqtNfnhTWUWf7X+dN7sD4pHk5n4OvkyMYgJ1PKutjtNga+JKMp7HenZGcewFlHqvSgYvlXCcsXoqvLv6WI9YZBTqb16uJqrD3SIuUpO+lpe1CQmyI9nFgTqzWJX6OxsTHs10uwGOREGisuLkZ6yjrpocSaeN1rOYeEFYtlX0ITxiAnQ+rq03axKi1tSEpEX8s56aHECqxOZm3H2bNnZV9GE8IgJ0Pp6B3GrPga/K+FlbKb4lFNTQ02rV8mPYxYgVfzTQdWr1oh+1KaEAY5GUbu1R78RLEm+I6T+nu+pcNxAhfy9kgPI1ZwtSV5laE++GSQk+519g5jdlLtmNsJ1xxukd20Mfbs3oVrF/ZLDyJWcLVu9WLcunVL9uXkNwY56dr+gq4xT+b5x88rcKlKnw9S2JOyA3U3jkkPIlZwtW/PBkMtW8AgJ11q6X6I1xJq3AL8x7+/hoPn9P3n7qaNSagpyZYeRKzgaoc9AWVlZbIvJ78xyEl3vjndgR+97d4LfyPRifYe/d6pIjDIzVEMcg0wyCNXck7rmLHwbbltspvlN3+D3J4UB4vFMqasM6Yjaspkt9eip03VNKTUxxfnsM6YPuZ12YHKIPcPg5x0paN3GD/+/ePe+PPvl+JG/YDsJk3IRILckZnsClZnSRacJVmwzpju9hr6ChE9bSpssTGah7k4PvoKXee1zpgOe1Ic0FcIW2xMQL9EHJnJrmMEUqItDHL/MchJd45c6MafNtbh4bDxHnoQyNCKOlTVr9mT4kLSKxfHVwanMsidJVkB9cqVx5hoOUuyEDVlMoN8ghjkRBoKRZBbZ0x365E7MpNdQx/OkizYYmNc/46aMtk1TOLrnMrhHE8h7OkXSNSUya6yzpjuNhwj2im+tsXGuLVVHe7iF4XyvehlWIdBrgEGORmVlkEuAs1TD1U5DCO+FqHuyEx2Ddv4c051kKvD1VP4enpdtFP5y0C85qunLfZhjzwwDHIKKxkrEYZTKHrk4+2HvkJXACp/AfgaU/d2fF/DIp6CVvTCPQW5+sNTT+dU9tgZ5IFhkFPYlDcM4IUPSrH68B3ZTQmZcAa5LTYGttgYj8FrnTF93P21CnLxQayvHrmnEsMuyn0Y5IFhkFNY7DrV7npq/eRZhSg12N0o/ppokHvqrSqHVcYbIhHDHGIb5Xi0CENPd7x4O75yWMVbj17sK4ZjoqdNdZ1PPU6uHiNXj3ur26seJ2eQ+49BTiHVPzjicZ0Uvc/QDBQnBJmjGOQaYJCbQ3XTIH724Q23AJ/67nWU3TJnbxxgkJulGOQaYJAb38FzXYh6s8gtxGfF1/DDTpYhikGuAQa5cT14OIrYLbfcAnzyrEJsyG6V3bSwSEvdhZrrDHKj1/5Urn4YNAa5MTW0DeGleeVuIf7snBJcrtbnkrOhwB65OYo9cg0wyI2psKYf37M+CfHfLqpCZ6/+VyzUkswgF3eBTHRdluhpU73eHePITNZ8eQAjFINcAwxy44rf34xJMwuxOL0JIyOyWxN+snvk4t5y2UFo9GKQa4BBbmwXyu/JboI0DHJzFINcAwxyMqqJBLl6gSkxGcY6Y7proo0Y8lBu62lGpnpCjrd91K8pF9wS57fFxrgm/Cgn/ygn8IjhFrGAlnISkOwQZpDrBIOcjMrfIHeWZLmNPYvQFg+ccGQmu3rXym3tSXFjVjZUT4n3to9yvFsZ1mK6vlgjXRnGyvN5m5qvnMVplvF0BrkGGOT61D84gqKa+7KboWsTebCEp+Vjla+LIFdPc1evRaJcN2W8fexJcR57zMoHW6in7ov2qNdA8fQ6g1weBjn5pbxhAD/78Ab++g8l6OqLrDtRJsLfIBdBq3wKkOgVq4Nc3XtXV/S0qa4eubKnrN7HkZnscUEqTwtoefoLQLmmuFisi0GuDwxy8ml3XofbLM3fLamW3STdCnSMXISi8iENyt6xclt1WCr3E2PryvFv5T7K4yqf06kc5xbnVx5XDLuoH0ahHJv3teCWkYpBrgEGuT4MDo1izvq6MbM0kzJbZDdNt2TftcJikOsGg1y+2pYHiP64LKJnaQaCQW6OYpBrgEEuV/bFbvzFfxS7hXgkztIMBIPcHMUg1wCDXI6h4VF8uqPBLcC/Zy1E/P7miJylGQgGuTmKQa4BBnn43RscwT9+XuEW4s/MLkHBjT7ZTTMUBrk5ikGuAQa5HK8l1LhC/DdfVqG9h0MpExVIkIs7Pnw9o9NXiclE4z1zU1nKu09EiTtXxnvEXCQUg1wDDHI57t57hGfnlGDZ3mbZTTGsid5+qHxOZ7BBLn4p+BvknmaJom/81RAjpRjkGmCQy9PTb+4n+ITaRIJcGd4Mcn0Vg1wDDHIyKn+DXEzcEcMYYgq9ejKO2E49IUe5toqY2KMMcvVUfvX51EEuzieOxyBnkAeNQR4a7G2HXjA9cjH70mKxuIJWGcbi32JavJi96chMdgWvGG8X4S0W4hKzLcUvA3WQq9dbYZAzyIPGINfejpPt+Ku3ik39BHs90GJoxVPQiteVJQJdOS1eObQiglw93KJc7dDTgljskTPINcEg1073vUf49+U3XXej/Dy2DA+HR2U3y7RCGeSeFrwSJQLZU5DbYmM89uzVC2Ipz88gZ5AHjUGujfzrvXh2TonbveH/fW4ZGjuGZDfNtCYS5GLc+uWX/s5tfNpiseCFqc+MGQ9XL02r/Fo5xq5exEp5LvVDJMTxlftGT5s67i+NSCgGuQYY5MF5ODyKL3Y3jpmh+XVaE3vjIcYJQeYoBrkGGOSBq215gJfmlbuF+PPvl6KwhotdhUPqnl24ySA3fGXsXo+qqirZl5PfGOQmstPR7hbgk2YWYt72BgwMcaGUcMlIT8WVgnTpQcQKrlYnfIXmZuNMjGOQm0B7zzB+/UWlW4D/dM51fHu9V3bTIk5BQQFOZW+THkSs4Cph+VcYGjLOZ0kMchMYHYXbcMof19XxnnFJ2trakLBsofQgYgVe5VcPY/u2zbIvpQlhkJtEddMgfhhTjD1nOmQ3JeJt3ZKMquLgp9uz5NSW5BWGGh8HGOSm0nufvXA9uHPnDnZsWSM9kFgTr9rrOUhLTZF9CU0Yg5woBC5fvoxNSYulBxPL/7rb+B3i5n8q+9IJCIOcKETq65zYuXU1hrsvSw8p1vhVW3oMC+Jssi+ZgDHIDWBTTivmbW+Q3QwKQFlZGT6zzcXZU3vQVpcnPbBY7lV+9TC2JCciNXW37EslKAxyHevpf4QZS5+sk3KysEd2kyhAZ86cQUL8UtiTV2HD2mVIT1mHHfbEcSvtmySf22hdGbvXh/2cYX+PKRuwKmEREpYvwvbtWw33waYnDHKdulTVP2adlF/FVcpuFgWps7MT9fX1qKioQFlZ2bjlzzZaV2VlZdjPGe6qqqpCc3Ozoe4T94VBrjOjo8Dqw3fw1Cz3GZrvb6rH4BDXSSGisRjkOnL33iP8bkm1W4D/4M1iZP65W3bTiEjHGOQ6UVo/gL/903W3EH9xbhnqWx/IbhoR6RyDXAe2nmjD068XuYX4nPV1GOKSs0TkBwa5ZPWtD8asWLjT0S67WURkIAxyHdie+3j52WfnlKCo5r7s5hCRwTDIdSLx4B209wzLbgYRGRCDnIjI4BjkREQGxyAnIjI4BnkYbMhuRWcvx7+JKDQY5CH0cHgUv19Ti0kzC/GLzyt4XzgRhYRmQW6322GxWOBwOGCxWGCzBb62rxmCvLN3GNMXuD8QecvxNtnNIiIT0izIrVYr7HY7HA7H4wNbAj+00YO8vvUBnnuv1C3Ev9jdiFF2yIkoBEIS5A6HA1FRUQEfy8hBfqW6Hz9555orwJ+aVYiD57pkN4uITEyzIBdDKqJEzzwQRg1yR1EP/pNizZS/fKsY58r6ZDeLiExOsyAPZkxczYhBnp7f6TaUMvXd66huGpTdLCKKAEEHudVqdeuJKytQRgryRyPAgpTbbiH+sq0cHbzdkIjChD1yDVhX1LhCPGa1k0/yIaKwCtl95FarNeB9jRbkDx6O4pX5FZidVCu7KUQUgTQL8ujo6IgcWhF67z+S3QQiilCa3n4IPBliicS7VoiIZNB8jFz8byQNrRARyaRpjzwqKgpOpxMWiwXR0dEBH4tBTkTkPy6a5SeOgRORXvGuFT/0DYzg+fdLsXxfs+ymEBGNEVSQK6fl2+121+s2m81Ud62IpWgnzSzEh/ZbsptDROQmqCBXLowl/m2xWILqjQP6CvKdjna3WZs7He1S20NEpBZUkCtnc4r1yJ1OZ9CN0kuQVzUO4vuvPVkE643E4N8bEZHWNAtysXytp+9NlB6C/NEI8OLcMleIP/9+Ke4NjkhpCxHReIIKcm+LZZlhZufaIy2uEP/+a0UouzUQ1vN3dHSgtrYWFRUVKC8v131VVlZKb4OMqqioQH19PXp7e8N6fRApadYjn8j3fJEd5Lfbh/C0Yl3xtUdaMBqmx/sUFBQgMWE5tmxeg41Jy5CyfQ22b07wq3ZuSfR7W60rI2W9tHPLrPSU9Vi/dhk2rkvExo3rcPXq1bBcJ0RKvI/cg3/+qsoV4i/OLcPICDA8PIyPPvwAp0450Nraqvk5+/v7kbxxLY5nbker8zTQV8gyWDVUnEB6ykbs2LEFIyMchqPwYZCr7CvodHtMW2n9kyGVAwf2YunXNiQs/wIrE5fh1KlTaG8P/i6WwcFBJKxYhP7W89LDiBV8NVc7sDJ+EYaHuSY9hQeDXGFgaATPzC5xBfnC3Y1jtjl//ixSd65B800HThzZgvhlC7F61QqcPn0aHR0dEz7nyMgIFn+9QHr4sLStnqYCrEpYosVlSeRTUEEu1lUJdm0VNZk98srGQfz6i0o8/36p1wdEFBUVYmvyiic9sJsOHD9sx4qlC7B65Qrk5fkf6hnpe3C1YK/04GFpX6eObsOJE8e0vDyJPAoqyJXhbbPZ3GZ3BkP2GDkAtN0d/8/iqqpKrFu9eMwPb1P1SVeor10dj7y8PHR2dno8Rnd3N9avXSY9cFihq5XxX3O8nEJO07tWtHrcmx6C3B8NDQ2IX7rQ6w/x7cpc5BzcjGWL47B2TQLOnDmDrq4u1/4XLlxAzsHN0sOGFbras2MNKisrJV6lFAk0DXL1eiuBMkqQA0B7ezu+XDjP5w90Y1Uucg7ZsWzxfCStXYn8/Hykpe3Ghbw90sOGFbrK3r8J+fn5si9TMjlOCNJAf38/Pv3kQwx2/NmvH+6GihM4emAzli2ej7a6POlhwwpdnT+9GydPnpR9iZLJBR3k3j7kjJQeuTAyMoK4zz9B9+18zcPAOmO6x1+USxa+O+Y1W2yMZud1lmR5PO+ct/81pOc1U+Wf2Ins7EzZlyeZXFBBHuwqh94YMciFJV9/geabDs2DXARr1JTJQF8h7ElxsCfFub2GvkJYLBY4MpM1DXPl8Z0lWbDFxmh2XnGsYP/b6LUY5BQOET1Fv/teaJ76s2rlctSUZGseCurw9PSadcZ0zXvl4viOzGTYk+I0PW/UlMkBB7k9KY5BToQIHiMfHQV+9uENzIqvQV3LA82Pvzl5HUovHQp7kEdNmezWM7bFxsBisbi2iZ421RWeYkhkvDBUD694C3L1ecV+0dOmehwGcpZkub4nevOireL7ynYoh5esM6bDkZn8ZA7DtKnSA5tBTjJFbI/8+JW7rhmcUW8WhWSJ2m92bsWl/PSQB7kyID2FshiGEduL10R4+ntOdY/cn/Oq2ytCWRxH/FIRwS728/bLRT28xB45UQSPkf/PzypcQR67JXSPb9u/Lw35ud+ENMg9haV6GxGSIriVQTze2La34/tzXk9Bq+7ZiyBX9rCVf0EoS/3XBYOc6LGQ3bUSjFAH+bfXe10h/j1rIRo7hjQ/h9LR7CM4fmSrtCBH3+MhFWWPWv29UAe5CGr0+e6Re2u/+kNWBjnRYxG5aNZvFz1ZpnbO+jrNj+/J6VMncSh9Y8CBoOyxiiBTD2/4ClXlNsrxaBGG6t65t+P7c17lNmIYR9l+9Ti5eoxcHepiO7GvcpycY+QU6SIuyG/UD7g9TLk2BB90eiNWTpQdLiwGOZlLxAX5nPV1rhB/LaFG02P7o7j4KrYmL5ceMCwGOZlHRAV5e88wJs960hs/V9an2bEnorKyAkmrFkkPGRaDnMwhooJ8SUaTK8Rfmleu2XED0dBwC9s2J+LR3cvSw4YVuvoudyeOHcuReq2R+UVMkA8Nj+In71xzBfnBc12+dwqxTZvWo/TSQelhwwpdsUdO4RAxQX6ysMcV4j+dc12TYwZr186tYQ1ycSeJVrfsibtMJrrGynh32IjbJGUHMIOcjCRighwASmrv4521tUjOadXsmMEIZ5CL8Nb63muzBS+DnIwoooJcb8IV5MrwZpAzyMl8GOQS+RvkYjKPmBCjHCJRTqhBn/tEH1tszJjFpUSQi/3E2ivqBavEIlVikS1le8T5o6ZMdgty5aQdZdB7WrRL+b5ssTGwJ8W52uCpTWJWp7f3rddikFM4MMglCqRHLoJchKCYESmCTjnLUXxf3SMfbz/ltlFTJnuc0q+cVq88h1jHRUzBF8cXAa5eP12cR7lwl7cp+8rzqNsvO6wZ5CQbg1yiiQS5smctglwZhKJXqxw2EYHqbWhF7OdtwSpPa4Wr11gRPXJl71n0msU0em/7K//S8PSLytd7YZATPcYgl8jfILfFxrh6p56CTh3IInyjp00ds62n/bwtWOXtoQ/Kc3jqkSvbrR6P97bwl/KvAOVqiOO9FwY50WMMcokmEuTK3vL3J09y6/l6eziDGBYRofjC1Gf82i962lTX9z2tcKjsSSvHvJUPihABKxa5Eq8pF71Sbi8CWnlO9XtRLsSlbr/swGaQk0wMconCfR85i0FO5mTaIG9oG8KClNsodt7XuHXaYZCbvxjkFA6mDfL4/c2umZwLUm5r3EJtMMjNXwxyCgdTBvnoKPDsnBJXkH97vTcErQweg9z8xSCncDBlkDuKnqyr8tx7pSFooTYY5OYvBjmFgymD/D9WOV1BvurQnRC0UBuBTgjy5xmdvkrc9eHp9kJ1ibte1JODxF0nssNSz8Ugp3AwXZB333uE71mfPFi57e5wiFoZvIkEubh32t+HLfv7S8GfIBfn9zTLk0HOICf5TBfkG7JbXb3xWfHhf5TbRPgb5MrwZpAbqxjkFA6mC/Kfx5a5gvzopbshaqE2/A1y5dR3EeRisoyYti4m54ht1Itgick0ytmWYi0V9RrlyvN5CnLlPgxyBjnJZ6ogv1533xXiP3r7GoYfjYawlcELtEeuXNlQTK0Xa5uIbdSLYNmT4lwzOMVxxeqFIrzFcZQrKSqPr170SgS67LDUczHIKRxMFeTzv7ntCvK5W2+FsIXaCHZoRR3k6in5npa+VU5pVw6tiEBWvqZeqVC9aJVyPxaDnOQxTZCPjgJ/M/vJveMXK++FuJXBy0jfg4qrRzQPcm+LYIlSL8ClDGSxzoo4vvi3slevPD+DfPw6f3o3Tpw4LvtSI5MzTZA3dgzhl3EVmDSzEC98oN97x5X27cvA5fw0vwJB2btWLxo1/RfRbuPh6CscswiW8msxDKN8OITYTn0u9LkvkqV+6ISWzwA1Yx07tAl5eXmyLzUyOdMEuVDX8gBnb/SFqGXa+vbbb5Gfu1N62LBCV1n7N+PatWuyLzUyOdMFuZE0NTVhdeJX0sOGFbqK++xjPHjwQPalRibHIJds4/o1qL2RIz1wWNrX5e/SsW9vmuxLjCIAg1yyhoYG7Nq2WnrosLSvdWuWYXBwUPYlRhGAQa4DdXVObF6/XHrwsLSrpNVL0dHRIfvSogjBINeJmzdvYsfWtagu9m/KPEufdbUgAxvWrWSIU1gxyHWkpaUFu7/Zhq+/+gw5h7bhxJGtOOtIQX7uTr+q4OQ3fm+rdU2knWaq86dTcPzwVmTt34oF8z9Betoe9Pf3y76UKMIwyHWop6cHV69exalTp5CTk4Ps7Gy/aiLbal25ubnSzi2zTpw4gTNnzqC4uBgDAwOyLx2KUIYO8qyL3Vic3oR8nT4BiIgoHAwd5K8urnZNyT90viuMLSQi0g/DBnlP/yM8NetxiD/9ehEGh/S90iERUagYNsh353W4euNvJDrD3EIiIv0wbJDPXH7TFeR7v+sMcwuJiPTDkEF+b3AET79ehEkzC/HUrELcGxyR0EoiIn0wZJAfPNfl6o3/bkm1hBYSEemHIYP8j+vqXEG+LbdNQguJiPTDcEE+MgL8MKbYFeStdx9KaiURkT4YLsj/XHHPFeIvzi2T1EIiIv0wXJAv3dvkCvKFuxsltZCISD8MF+QXK+/h81238dK8cjiKeiS1kIhIPwwX5ERE5I5BTkRkcAxyIiKDY5ATERkcg5yIyOAY5EREBscgJyIyOAY5EZHBGSbI4765ja9SG5GR34l+LltLRORimCD/wZtPFsoaGGKQExEJhgjymuYHrhB/7r1S2c0jItIVQwT5kQvdfD4nEZEXhgjyJRlPVjxcsb9ZdvOIiHTFEEFuXVHjCvKjl+7Kbh4Rka4YIsife6/UFeTOOw9kN4+ISFd0H+Rnz190hfjTrxdhdFR264iI9EX3QZ6WfckV5C/NK5fdNCIi3dF9kMd/c9kV5H9IqpXdNCIi3dF9kL+/5ooryBMP3pHdNCIi3dF9kE0WVpkAAAN1SURBVP/vBU+CPOtit+ymERHpju6DfHfmZewv6EJyTiuaux7KbhoRke7oPsi5+iER0fgY5EREBscgJyIyOAY5EZHBMciJiAyOQU5EZHAMciIig2OQExEZnG6D/H/88lX85NUd+CjpCvKu9cpuEhGRbuk2yKP/6R3X1PyXbVz1kIjIG90G+X/99TxXkMes5nM6iYi80W2Q/+1vl7mC/KvURtlNIiLSLd0G+V+/usUV5Dsd7bKbRESkW7oN8r/4PwdcQX6mhB92EhF5o9sg//6Mb11BXtfCBy4TEXmjyyCfv+BLV4hPnlWIkRHZLSIi0i9dBvl7tpWuIP/p7Cuym0NEpGu6DPLXYze5gvxXNgY5EdF4dBnkv343xRXk78Rflt0cIiJdCzrIbTYbLBaLW9lstqCO+U/vpuKpf/8zJs0sxPO/me9ad4XFYrGUlZqaGmyEmUJQQW61Wj2Gts1mg9VqDfi4R48exaJFi/APv/o3vPzLf5F+sbBYLH0Wg/yxoIJ8vJ53sL3yqqoq6RcJi8XSdzHIHwu6R+5wOMa87nQ6ER0dHcyhiYjIT0GPkUdHR48ZI4+KitKibURE5Add3rVCRET+Y5ATERkcg5yIyOAY5EREBscgp5CxWq1jPgi3WCweX/dn32BvaSUyKwY5hZTVaoXdbnf7Wv26zWbzeLuqel+LxQKn0/tj/2w227jfJzIrBjmFlDKMlbN9la87nU6vvXJf2yhFRUUxyCkiMcgppJRDJMr5BcqQttvtXnvk3uYmREVFub4n9hdfOxwOtzWAGO5kdgxyCqnxeuTK8W9PYSv2tVqtXtfuEd8HnvTIlTOLld8nMitdBbnoZSnHRcnY1OPcvl73to3oaSuJXrg6yB0OB2cam4zIBv515Zluglz5Q8sfPPPQKsjtdrvbdSGC3VePnMyDn4F4p5sgV/6Q2mw29spNQDl8orx10NvrvvYVrynHw5V/xYnX1WPkDHVzYJB7p9sg5z3DRKTEIPeOQU5EhsAg906XQe7P+CkRRRYGuXe6CXJ+2ElE42GQe6ebIAfgNsGDiEhQTgCjsfhfhYjI4BjkREQGxyAnIjI4BjkRkcExyImIDI5BTkRkcAxyIiKDY5ATERkcg5yIyOAY5EREBscgJyIyOAY5EZHBMciJiAyOQU5EZHAMciIig2OQExEZ3P8HFbSlFhndhs8AAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO3gQILJnr_U"
      },
      "source": [
        "#AUROC = Area Under the Receiver Operating Characteristic curve\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob[:,1])\n",
        "print('AUCROC: %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wOOM6cIpGlx"
      },
      "source": [
        "Generate FPR and TPR at different thresholds using the `roc_curve` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfaVA2XhpDuB"
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ZgrSmFpOp8"
      },
      "source": [
        "y_test.shape, thresholds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aENFufv2pUK4"
      },
      "source": [
        "DataFrame showing three columns: FPR, TPR and Threshold. This represents different values of FPR and TPR at different thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koTHNphepSDM"
      },
      "source": [
        "pd.DataFrame([fpr,tpr,thresholds]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsE7mnWSpmKk"
      },
      "source": [
        "#Function to plot ROC curve  \n",
        "def plot_roc(y_test, predictions, title):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "    roc_auc = auc(fpr, tpr)  \n",
        "    print('AUROC: %.3f' % roc_auc)\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], '--')\n",
        "    plt.xlim([0.0, 1.05])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9kgjcVYp9I2"
      },
      "source": [
        "Let's plot the ROC curves for a perfect classifier, classifier based on random guessing and our trained model : Logistic regression. The area under the ROC curve is the AUC-ROC metric. A perfect classifier has AUCROC = 1 and random guessing will have a AUCROC around 0.5. \n",
        "Our trained Logistic Regression classifier has a AUCROC of 0.8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9isZxq4plBp"
      },
      "source": [
        "plot_roc(y_test, y_test,\"Perfect Classifier\")\n",
        "plot_roc(y_test, np.random.uniform(0, 1, len(y_test)) ,\"Random Guessing\")\n",
        "plot_roc(y_test ,y_pred_prob[:,1], \"Logistic Regression\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X181_DQrrD4f"
      },
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfa18FqGrIEY"
      },
      "source": [
        "You can also generate the precision, recall, and f1 scores using classification_report. \n",
        "\n",
        "* Scores of every class correspond to the accuracy of the classifier in classifying that particular class compared to the other class.\n",
        "\n",
        "* The support is the number of samples of the true response that are in that class.\n",
        "\n",
        "* The last line gives a weighted average of precision, recall and f1-score where the weights are the support values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7wgGghq_S4"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kEtNr82rMPG"
      },
      "source": [
        "### Trying Other classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsYSleS3rYa_"
      },
      "source": [
        "Let's try some other classifiers. We will run \n",
        "* Random Forest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "* Support Vector Machine : https://scikit-learn.org/stable/modules/svm.html, https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
        "\n",
        "\n",
        "in addition to Logistic Regression and compare models based on the different metrics we discussed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfn4v5AJrZRN"
      },
      "source": [
        "#Fit the model\n",
        "#model = LogisticRegression(solver='lbfgs')\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "#model = svm.SVC(probability=True)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Prediction\n",
        "predictions_proba = model.predict_proba(X_test)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "#Getting the confusion matrix for the new \n",
        "cm = confusion_matrix(y_test,predictions)\n",
        "plot_confusion_matrix(conf_mat=cm, show_absolute=True)\n",
        "plt.show()\n",
        "\n",
        "#Let's print the classification\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "#Getting the metrics\n",
        "show_metrics(y_test, predictions)\n",
        "\n",
        "#Compute and print AUC-ROC Curve\n",
        "roc_auc = roc_auc_score(y_test, predictions_proba[:,1])\n",
        "print('AUCROC: %.3f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOs6fKlrs8e2"
      },
      "source": [
        "## Feature Importance using Tree-Based Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGYZ6TZqtoAn"
      },
      "source": [
        "We will a tree based ensemble classifier: **XGBoost**, which is very a popular ML model to output feature importance. A benefit of using ensembles of decision tree methods like gradient boosting is that they can automatically provide estimates of feature importance from a trained predictive model. Generally, importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions with decision trees, the higher its relative importance.\n",
        "\n",
        "XGGBoost Documentation: https://xgboost.readthedocs.io/en/latest/\n",
        "Check this article for more information on feature importance usinfg XGBoost: https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr4UH4CLs5Ep"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrt9CLUntMeW"
      },
      "source": [
        "# fit model no training data\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaKGlzyctNDq"
      },
      "source": [
        "# plot feature importance\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plot_importance(model, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}